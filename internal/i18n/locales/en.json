{
  "app.version": "ollama-remote {version}",
  "app.version_commit": "ollama-remote {version} ({commit})",

  "help.usage": "Usage: {app} [--host <url>] [--lang <en|es|de>] [--ollama-exe <path>] [--config <path>] <command|ollama-args...>",
  "help.what_is": "A small wrapper that runs the official Ollama CLI against a configured OLLAMA_HOST.",
  "help.global_flags": "Global flags:",
  "help.flag.host": "  --host <url>          Override OLLAMA_HOST for this invocation",
  "help.flag.lang": "  --lang <en|es|de>     Language for this tool's output",
  "help.flag.ollama_exe": "  --ollama-exe <path>  Path to the Ollama CLI (otherwise uses PATH)",
  "help.flag.config": "  --config <path>       Use only this config file (skip auto-discovery)",
  "help.flag.help": "  -h, --help            Show this help",
  "help.flag.version": "  --version             Show version",
  "help.wrapper_cmds": "Wrapper commands:",
  "help.cmd.config": "  config [show|set|init|path]  Manage user config",
  "help.cmd.doctor": "  doctor                      Check basic setup",
  "help.cmd.ui": "  ui                          Launch the optional local web UI",
  "help.examples": "Examples:",
  "help.example.list": "  ollama-remote list",
  "help.example.run": "  ollama-remote run llama3:8b",
  "help.example.host": "  ollama-remote --host https://ollama.example.com:11434 ps",
  "help.example.lang": "  ollama-remote --lang de doctor",
  "help.example.ui": "  ollama-remote ui",
  "help.try_help": "Try: {app} --help",

  "config.path": "Config path: {path}",
  "config.host": "host = {value}",
  "config.lang": "lang = {value}",
  "config.ollama_exe": "ollama_exe = {value}",
  "config.no_proxy_auto": "no_proxy_auto = {value}",
  "config.value.auto": "auto",
  "config.inited": "Created config: {path}",
  "config.set_ok": "Updated: {key}",

  "doctor.host": "Host: {value}",
  "doctor.lang": "Language: {value}",
  "doctor.ollama_failed": "Failed to run Ollama: {error}",

  "ui.started": "UI: {url}",
  "ui.stop_hint": "Press Ctrl+C to stop.",

  "ui.subtitle": "Local UI for the official Ollama CLI. Runs on your machine only.",
  "ui.section.config": "Config",
  "ui.section.pull": "Pull model",
  "ui.section.run": "Run prompt",
  "ui.section.output": "Output",
  "ui.label.host": "Host",
  "ui.label.language": "Language",
  "ui.label.model": "Model",
  "ui.label.prompt": "Prompt",
  "ui.btn.list": "List models",
  "ui.btn.save": "Save",
  "ui.btn.pull": "Pull",
  "ui.btn.run": "Run",
  "ui.placeholder.host": "http://127.0.0.1:11434",
  "ui.placeholder.model": "llama3:8b",
  "ui.placeholder.prompt": "Write a short incident postmortem...",
  "ui.message.saved_restart": "Saved. Restart the UI to fully apply language changes.",
  "ui.error.unauthorized": "Unauthorized",
  "ui.error.bad_request": "Bad request",
  "ui.error.model_required": "Model is required",

  "error.invalid_args": "Error: {error}",
  "error.arg.unknown_flag": "Unknown flag: {flag}",
  "error.arg.missing_value": "{flag} requires a value",
  "error.unknown_subcommand": "Unknown subcommand: {sub}",
  "error.config_load": "Failed to load config ({path}): {error}",
  "error.config_init": "Failed to create config ({path}): {error}",
  "error.config_set_usage": "Usage: ollama-remote config set <host|lang|ollama_exe|no_proxy_auto> <value>",
  "error.config_unknown_key": "Unknown config key: {key}",
  "error.config_set": "Failed to update config: {error}",
  "error.env_build": "Failed to prepare environment: {error}",
  "error.ollama_not_found": "Ollama CLI not found. Install Ollama or set OLLAMA_EXE. {hint}",
  "error.ollama_failed": "Ollama failed: {error}",
  "error.ui_listen": "Failed to listen: {error}",
  "error.ui_start": "Failed to start UI: {error}"
}
